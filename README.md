
# MVP - Machine Learning para Diagn√≥stico de C√¢ncer de Mama

## Objetivo
A etapa de avalia√ß√£o tem como objetivo analisar o desempenho dos modelos treinados em dados n√£o vistos, ou seja, a base de teste. Isso garante que o modelo n√£o apenas decorou os exemplos do treino, mas generalizou bem para novos casos.

Neste projeto, os modelos foram treinados com 70% dos dados e avaliados em 30% de dados reservados exclusivamente para teste.

## Dataset
- **Nome:** Breast Cancer Wisconsin (Diagnostic)
- **Origem:** [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29)
- **Tamanho:** ~50 KB
- **Caracter√≠sticas:** 569 amostras e 30 vari√°veis explicativas.

## Tecnologias
- Python 3.10
- Pandas, NumPy, Scikit-learn
- Matplotlib, Seaborn

## Escolha das M√©tricas de Avalia√ß√£o
| **M√©trica**                | **Por que usar**                                                                                                               |
| -------------------------- | ------------------------------------------------------------------------------------------------------------------------------ |
| **Accuracy (Acur√°cia)**    | Mede a propor√ß√£o de previs√µes corretas sobre o total de casos. √ötil quando as classes est√£o balanceadas.                       |
| **Precision (Precis√£o)**   | Mede a qualidade das previs√µes **positivas**. Importante para evitar falsos positivos, que podem gerar alarmes desnecess√°rios. |
| **Recall (Sensibilidade)** | Mede a capacidade do modelo em detectar **casos realmente malignos**. Essencial em diagn√≥sticos m√©dicos.                       |
| **F1-Score**               | M√©dia harm√¥nica entre *Precision* e *Recall*. Ideal quando precisamos equilibrar falsos positivos e falsos negativos.          |
| **Matriz de Confus√£o**     | Mostra o desempenho detalhado, evidenciando onde ocorrem erros de classifica√ß√£o.                                               |


## Estrutura do projeto
```
mvp_breast_cancer/
‚îÇ
‚îú‚îÄ‚îÄ notebook_mvp.ipynb      # Notebook completo
‚îú‚îÄ‚îÄ README.md                # Documenta√ß√£o do projeto
‚îî‚îÄ‚îÄ requirements.txt         # Lista de depend√™ncias
```

## Treinamento Final do Modelo
Ap√≥s comparar tr√™s modelos iniciais (Logistic Regression, Decision Tree, Random Forest), o Random Forest apresentou o melhor desempenho e foi selecionado para otimiza√ß√£o com GridSearchCV.

C√≥digo usado para treino final:
final_model = grid.best_estimator_
final_model.fit(X_train_scaled, y_train)

## Teste com a Base de Teste
O modelo final foi avaliado usando o 30% de dados reservados para teste, que n√£o participaram do treino.

y_pred_final = final_model.predict(X_test_scaled)

from sklearn.metrics import classification_report, confusion_matrix

print(classification_report(y_test, y_pred_final))
sns.heatmap(confusion_matrix(y_test, y_pred_final), annot=True, fmt='d', cmap='Blues')
plt.xlabel("Previsto")
plt.ylabel("Real")
plt.show()

## Resultados Obtidos
## Relat√≥rio de Classifica√ß√£o:
| M√©trica                 | Valor             |
| ----------------------- | ----------------- |
| **Accuracy**            | **0.982** (98,2%) |
| **Precision (Maligno)** | **0.97**          |
| **Recall (Maligno)**    | **0.98**          |
| **F1-Score (Maligno)**  | **0.98**          |
| **F1-Score Geral**      | **0.98**          |

## Matriz de Confus√£o:
| **Real \ Previsto** | **Benigno (0)** | **Maligno (1)** |
| ------------------- | --------------- | --------------- |
| **Benigno (0)**     | 107             | 2               |
| **Maligno (1)**     | 1               | 61              |

## Os Resultados Fazem Sentido?
Sim, os resultados fazem sentido porque:

1. A acur√°cia est√° alta (98,2%), mas n√£o √© a √∫nica m√©trica analisada.
2. Recall alto (98%) indica que o modelo identifica quase todos os tumores malignos, essencial em sa√∫de.
3. O n√∫mero de falsos negativos √© muito baixo (apenas 1 caso), mostrando boa capacidade de detec√ß√£o.
4. O modelo n√£o apresentou overfitting, pois a performance no treino foi similar ao teste.

üí° Apesar do excelente desempenho, em ambientes reais de sa√∫de, modelos como este devem ser usados apenas como suporte ao diagn√≥stico, nunca como decis√£o final.

## Conclus√µes da Avalia√ß√£o
O Random Forest otimizado se mostrou altamente eficaz na classifica√ß√£o de tumores de mama.
Mesmo com m√©tricas excelentes, o √∫nico falso negativo exige aten√ß√£o: em diagn√≥sticos m√©dicos, Recall deve ser maximizado.
Melhorias futuras:
Coletar mais dados cl√≠nicos para treinar o modelo.
Explorar Redes Neurais Profundas (Deep Learning) para aumentar Recall.
Aplicar t√©cnicas de balanceamento como SMOTE, caso classes fiquem desbalanceadas em bases futuras.
Implementar um ensemble h√≠brido, combinando Random Forest com outros modelos.

## Resumo Final
O modelo atingiu:
1. 98,2% de acur√°cia,
2. 98% de Recall,
3. e apenas 1 falso negativo, mostrando grande potencial para ser aplicado como ferramenta auxiliar na detec√ß√£o de c√¢ncer de mama, apoiando profissionais da sa√∫de na tomada de decis√µes cr√≠ticas.

---
**Autor:** Carlos Eduardo Silva dos Santos  
**Disciplina:** Privacidade e Seguran√ßa Cibern√©tica  
**Professor:** Dr. Andr√© Serrano
